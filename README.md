# PYSPARK-
Implemented a real-world, scenario-based data engineering problem using PySpark and Databricks Delta Lake. The project demonstrates end-to-end data pipeline development including:

ğŸ”¹Data ingestion from source tables
ğŸ”¹Deduplication and transformation of records
ğŸ”¹Handling Slowly Changing Dimensions with Delta Live Tables (DLT)
ğŸ”¹Ensuring data consistency, reliability, and scalability for analytics

This project simulates challenges faced in industry workflows and showcases best practices in modern data engineering.

ğŸ“Š Key Features:
âœ… Deduplication and handling of late-arriving data
âœ… Maintenance of historical records with SCD Type 2
âœ… Streaming & batch integration for real-time analytics
âœ… Data validation and monitoring for data quality assurance

ğŸ›  Tech Stack:
âš¡ PySpark / Spark SQL
ğŸ’ Databricks / Delta Lake / DLT
ğŸ Python
